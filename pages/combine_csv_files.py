ØµÙØ­Ø©: Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (Ù…Ø«Ù„Ø§Ù‹ 30 Ù…Ù„Ù)

Ø§Ù„Ù…Ø³Ø§Ø±: pages/merge_sensor_files.py

import streamlit as st import pandas as pd import base64 import os

st.set_page_config(page_title="Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª", page_icon="ğŸ—‚ï¸", layout="wide") st.title("ğŸ—‚ï¸ Ø¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª - Ø¯ÙØ¹Ø© Ø¨Ø¯ÙØ¹Ø©")

Ù…Ù„Ù Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

TEMP_FILE_PATH = "data/combined_sensor_data.csv" os.makedirs("data", exist_ok=True)

Ø±ÙØ¹ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª (Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 30)

uploaded_files = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ø¯ÙØ¹Ø© Ù…Ù† Ù…Ù„ÙØ§Øª CSV (Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 30)", type=["csv"], accept_multiple_files=True)

if uploaded_files: if len(uploaded_files) > 30: st.error("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ 30 Ù…Ù„Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ ÙÙŠ ÙƒÙ„ Ø¯ÙØ¹Ø©") else: all_new_data = [] for file in uploaded_files: try: df = pd.read_csv(file) all_new_data.append(df) except Exception as e: st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ù {file.name}: {e}")

if all_new_data:
        new_batch = pd.concat(all_new_data, ignore_index=True)
        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ {len(uploaded_files)} Ù…Ù„Ù.")
        st.dataframe(new_batch.head())

        if os.path.exists(TEMP_FILE_PATH):
            existing_df = pd.read_csv(TEMP_FILE_PATH)
            combined_df = pd.concat([existing_df, new_batch], ignore_index=True)
        else:
            combined_df = new_batch

        combined_df.to_csv(TEMP_FILE_PATH, index=False)
        st.success("ğŸ“ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¬Ù…Ø¹ Ø¨Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©")

Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬

if os.path.exists(TEMP_FILE_PATH): st.markdown("---") st.subheader("ğŸ“¦ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†") temp_df = pd.read_csv(TEMP_FILE_PATH) st.write(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {temp_df.shape[0]}") st.dataframe(temp_df.head())

# Ø²Ø± Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
if st.button("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"):
    cleaned_df = temp_df.dropna(how='all')
    cleaned_df.drop_duplicates(inplace=True)

    st.success("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ÙˆØ§Ù„Ù…ÙƒØ±Ø±Ø©")
    st.write(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {cleaned_df.shape[0]}")

    # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„
    csv = cleaned_df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="clean_sensor_data.csv">â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ØªØ¯Ø±ÙŠØ¨</a>'
    st.markdown("### ğŸ“¥ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„")
    st.markdown(href, unsafe_allow_html=True)

    # Ø­ÙØ¸Ù‡ Ø£ÙŠØ¶Ù‹Ø§ Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§ Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
    cleaned_df.to_csv("data/clean_sensor_data.csv", index=False)

