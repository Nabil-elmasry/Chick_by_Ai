import streamlit as st
import pandas as pd
import os
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from modules.preprocessing import prepare_training_data
from modules.model import train_and_save_model

st.title("ğŸš— ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø·Ø§Ù„")

Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ†

sensor_file = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª (Sensor Data)", type=["csv"], key="sensor") carset_file = st.file_uploader("ğŸ“¤ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ (Carset Data)", type=["csv"], key="carset")

if sensor_file and carset_file: sensor_df = pd.read_csv(sensor_file) carset_df = pd.read_csv(carset_file)

# Ø²Ø±Ø§Ø± Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ ID
if st.button("â• Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ record_id Ù„Ù„Ù…Ù„ÙØ§Øª"):
    sensor_df.insert(0, 'record_id', range(1, 1 + len(sensor_df)))
    carset_df.insert(0, 'record_id', range(1, 1 + len(carset_df)))

    sensor_df.to_csv("data/sensor_with_id.csv", index=False)
    carset_df.to_csv("data/carset_with_id.csv", index=False)

    st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ record_id ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")

# Ø²Ø±Ø§Ø± Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
    try:
        # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ record_id
        merged_df = pd.merge(sensor_df, carset_df, on="record_id", how="inner")
        merged_df.to_csv("data/merged_training_data.csv", index=False)

        st.info("ğŸ”„ ØªÙ… Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­")

        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X, y = prepare_training_data(sensor_df, carset_df)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = train_and_save_model(X_train, y_train, model_path="model/fault_model.pkl")

        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        matrix = confusion_matrix(y_test, y_pred)

        st.success("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")

        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        st.subheader("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…")
        st.text(report)

        fig, ax = plt.subplots()
        sns.heatmap(matrix, annot=True, fmt="d", cmap="Blues", ax=ax)
        ax.set_title("Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³")
        ax.set_xlabel("Ø§Ù„ØªÙˆÙ‚Ø¹")
        ax.set_ylabel("Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ")
        st.pyplot(fig)

        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠÙ‹Ø§
        with open("data/evaluation_report.txt", "w") as f:
            f.write(report)

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©
        st.subheader("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©")
        with open("model/fault_model.pkl", "rb") as f:
            st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨", f, file_name="fault_model.pkl")
        with open("data/merged_training_data.csv", "rb") as f:
            st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬", f, file_name="merged_training_data.csv")
        with open("data/evaluation_report.txt", "rb") as f:
            st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", f, file_name="evaluation_report.txt")

    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")

else: st.warning("âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ø¨Ø¯Ø¡")

