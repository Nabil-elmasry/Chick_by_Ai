# pages/train_model.py

import streamlit as st
from modules.data_loader import load_sensor_data, load_carset
from modules.preprocessing import prepare_training_data
from modules.model import train_and_save_model
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import os

st.set_page_config(page_title="ğŸ“Š ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", layout="wide")
st.title("ğŸ“Š ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ØªÙ†Ø¨Ø¤ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„")

sensor_file = st.file_uploader("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª (sensor data)", type=["csv"])
carset_file = st.file_uploader("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Carset (Ø¨Ù‡ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©)", type=["csv"])

# Ø®Ø·ÙˆØ© 1: Ø²Ø± Ù„Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ ID
if st.button("Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ ID ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§"):
    if sensor_file and carset_file:
        try:
            sensor_df = pd.read_csv(sensor_file)
            carset_df = pd.read_csv(carset_file)

            sensor_df["record_id"] = range(1, len(sensor_df) + 1)
            carset_df["record_id"] = range(1, len(carset_df) + 1)

            os.makedirs("data", exist_ok=True)
            sensor_path = "data/sensor_with_id.csv"
            carset_path = "data/carset_with_id.csv"
            sensor_df.to_csv(sensor_path, index=False)
            carset_df.to_csv(carset_path, index=False)

            st.success("ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ ID ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­.")
            st.info(f"ØªÙ… Ø§Ù„Ø­ÙØ¸: {sensor_path}, {carset_path}")
            st.session_state["ready_for_training"] = True
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯: {e}")
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹.")

# Ø®Ø·ÙˆØ© 2: Ø²Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
if st.session_state.get("ready_for_training"):
    if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
        try:
            sensor_df = pd.read_csv("data/sensor_with_id.csv")
            carset_df = pd.read_csv("data/carset_with_id.csv")

            # Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
            X, y, merged_df = prepare_training_data(sensor_df, carset_df)
            merged_df.to_csv("data/training_data_log.csv", index=False)
            st.success("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…Ø¬ Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")

            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model = train_and_save_model(X, y)

            # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            y_pred = model.predict(X)
            report = classification_report(y, y_pred, output_dict=False)
            matrix = confusion_matrix(y, y_pred)

            with open("data/evaluation_report.txt", "w", encoding="utf-8") as f:
                f.write(report)

            st.subheader("ØªÙ‚Ø±ÙŠØ± Ø¯Ù‚Ø© Ø§Ù„ØªÙˆÙ‚Ø¹")
            st.text(report)
            st.success("ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")

            # Ø±Ø³Ù… Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³
            st.subheader("Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ù„ØªØ¨Ø§Ø³")
            fig, ax = plt.subplots()
            sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', ax=ax)
            st.pyplot(fig)

        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")