
# pages/train_model.py

import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

st.set_page_config(page_title="ğŸ“Š ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", layout="wide")

st.title("ğŸ“Š ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ØªÙ†Ø¨Ø¤ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„")
st.write(
    """
    ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ù…Ù„Ù Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙ…Ù„Ù Carset Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª (Fault Codes)ØŒ
    Ø«Ù… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù€ Random Forest ÙˆØ­ÙØ¸Ù‡ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.
    """
)

# Ø±ÙØ¹ Ù…Ù„ÙØ§Øª CSV
sensor_file = st.file_uploader(
    "1. Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª (sensor dataset)", type=["csv"], key="sensor_file"
)
carset_file = st.file_uploader(
    "2. Ø§Ø±ÙØ¹ Ù…Ù„Ù Carset (carset.csv)", type=["csv"], key="carset_file"
)

if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
    if sensor_file is None or carset_file is None:
        st.error("âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨.")
    else:
        try:
            with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                sensor_df = pd.read_csv(sensor_file)
                carset_df = pd.read_csv(carset_file)

                if 'id' not in sensor_df.columns or 'id' not in carset_df.columns:
                    st.error("âŒ Ø§Ù„Ù…Ù„ÙØ§Øª ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'id'. ÙŠØ±Ø¬Ù‰ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ ÙÙŠ ØµÙØ­Ø© Ø§Ù„Ø¯Ù…Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
                    st.stop()

                # Ø§Ù„Ø¯Ù…Ø¬ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³ id
                merged_df = pd.merge(sensor_df, carset_df, on="id")
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")

            st.subheader("ğŸ§® Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
            input_features = st.multiselect("ğŸ”§ Ø§Ø®ØªØ± Ø§Ù„Ø®ØµØ§Ø¦Øµ (features)", merged_df.columns.tolist())
            target_column = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù (target)", merged_df.columns.tolist())

            if input_features and target_column:
                with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    X = merged_df[input_features]
                    y = merged_df[target_column]
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                    model = RandomForestClassifier()
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)

                st.success("ğŸ‰ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­.")
                st.subheader("ğŸ“ˆ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡")
                st.text(classification_report(y_test, y_pred))

                # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                import joblib
                joblib.dump(model, "fault_model.pkl")
                st.success("ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ `fault_model.pkl`.")

            else:
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®ØµØ§Ø¦Øµ ÙˆØ§Ù„Ù‡Ø¯Ù.")

        except Exception as e:
            st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")


# Ø²Ø± Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                with open("fault_model.pkl", "rb") as f:
                    st.download_button(
                        label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨",
                        data=f,
                        file_name="fault_model.pkl",
                        mime="application/octet-stream"
                    )

