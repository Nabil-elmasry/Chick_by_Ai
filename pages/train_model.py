import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import base64

st.set_page_config(page_title="ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", layout="wide")
st.title("âœ¨ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ - Ø®Ø·ÙˆØ§Øª Ù…Ù†Ø¸Ù…Ø©")

# ===== 1ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© =====
st.header("1ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø¨Ø¯ÙˆÙ† record_id)")
sensor_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠ", type="csv", key="sensor_original")
carset_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ", type="csv", key="carset_original")

if sensor_file and carset_file:
    sensor_df = pd.read_csv(sensor_file)
    carset_df = pd.read_csv(carset_file)
    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
    st.dataframe(sensor_df.head())
    st.dataframe(carset_df.head())

    if st.button("â• Ø£Ø¶Ù Ø¹Ù…ÙˆØ¯ record_id"):
        sensor_df["record_id"] = range(1, len(sensor_df) + 1)
        carset_df["record_id"] = range(1, len(carset_df) + 1)
        st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ record_id")

        # Ø­ÙØ¸ ÙŠØ¯ÙˆÙŠ - Ø±ÙˆØ§Ø¨Ø· ØªØ­Ù…ÙŠÙ„
        def download_link(df, filename, label):
            csv = df.to_csv(index=False)
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{label}</a>'
            return href

        st.markdown(download_link(sensor_df, "sensor_with_id.csv", "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø¯Ù„"), unsafe_allow_html=True)
        st.markdown(download_link(carset_df, "carset_with_id.csv", "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù„"), unsafe_allow_html=True)

# ===== 2ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ =====
st.header("2ï¸âƒ£ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„Ø© (Ø¨Ù‡Ø§ record_id)")
sensor_id_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø¯Ù„", type="csv", key="sensor_id")
carset_id_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¹Ø¯Ù„", type="csv", key="carset_id")

if sensor_id_file and carset_id_file:
    sensor_id_df = pd.read_csv(sensor_id_file)
    carset_id_df = pd.read_csv(carset_id_file)

    if st.button("ğŸ”— Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙÙŠÙ†"):
        merged_df = pd.merge(sensor_id_df, carset_id_df, on="record_id", how="inner")
        st.success("âœ… ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
        st.dataframe(merged_df.head())

        # Ø­ÙØ¸ ÙŠØ¯ÙˆÙŠ Ù„Ù…Ù„Ù Ø§Ù„Ø¯Ù…Ø¬
        st.markdown(download_link(merged_df, "merged_data.csv", "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¯Ù…Ø¬"), unsafe_allow_html=True)

# ===== 3ï¸âƒ£ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¯Ù…Ø¬ =====
st.header("3ï¸âƒ£ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
merged_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", type="csv", key="merged_final")

if merged_file:
    merged_df = pd.read_csv(merged_file)
    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù")
    st.dataframe(merged_df.head())

    # ===== 4ï¸âƒ£ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Processing =====
    st.header("4ï¸âƒ£ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Processing)")
    if st.button("âš™ï¸ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
        try:
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            if "fault_code" not in merged_df.columns or "record_id" not in merged_df.columns:
                st.error("âŒ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: fault_code, record_id")
            else:
                X = merged_df.drop(columns=["fault_code", "record_id"])
                y = merged_df["fault_code"]
                st.success("âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
                st.dataframe(X.head())

                # ===== 5ï¸âƒ£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ =====
                st.header("5ï¸âƒ£ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
                if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"):
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                    model = RandomForestClassifier()
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    report = classification_report(y_test, y_pred)
                    st.success("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
                    st.code(report)

                    # Ø­ÙØ¸ ÙŠØ¯ÙˆÙŠ Ù„Ù„ØªÙ‚Ø±ÙŠØ±
                    b64_report = base64.b64encode(report.encode()).decode()
                    st.markdown(f'<a href="data:file/txt;base64,{b64_report}" download="model_results.txt">ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…</a>', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ùˆ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")